{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adarabi3\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "from matplotlib.pyplot import imshow\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=[]\n",
    "datadir=\"C:/Users/adarabi3/OneDrive - Georgia Institute of Technology/Documents/MATLAB/Lens_data/Image_output/\"\n",
    "path = os.path.join(datadir)\n",
    "image_list = os.listdir(path)\n",
    "for img in image_list:\n",
    "    image_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "    image_array2=cv2.resize(image_array,(100,100))\n",
    "    # plt.imshow(image_array,cmap=\"gray\")\n",
    "    # plt.show()\n",
    "    # break\n",
    "    training_data.append([image_array2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21000, 11)\n",
      "(21000, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "X=[]\n",
    "for features in training_data:\n",
    "    X.append(features)    \n",
    "X=np.array(X).reshape(-1,100,100,1)\n",
    "Y_train = pd.read_csv(\"Data_param.csv\")\n",
    "Y= Y_train.to_numpy().reshape(-1,11)\n",
    "print(Y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 100, 100, 1)\n",
      "(1000, 100, 100, 1)\n",
      "(200, 11)\n",
      "(1000, 11)\n"
     ]
    }
   ],
   "source": [
    "x_train=X[0:200]#20000]\n",
    "x_test=X[20000:21001]\n",
    "y_train=Y[0:200]#20000]\n",
    "y_test=Y[20000:21001]\n",
    "x_train=x_train/255\n",
    "x_test=x_test/255\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    \"\"\"\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    # Second component of main path\n",
    "    X = Conv2D(F2,  kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path \n",
    "    X = Conv2D(F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    ##### SHORTCUT PATH #### \n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X) \n",
    "    \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (400, 400, 1), classes = 10):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*2-> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (2, 2), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    # picture becomes 100*100*16\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), strides=(2, 2))(X)\n",
    "    # piture bcomes 25*25*64\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [16, 16, 32], stage = 2, block='a', s = 1)\n",
    "    # X = identity_block(X, 3, [8, 8, 16], stage=2, block='b')\n",
    "    # picture becomes 13*13*16\n",
    "\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f=3, filters=[32, 32, 64], stage=3, block='a', s=2)\n",
    "    # X = identity_block(X, 3, [16, 16, 32], stage=3, block='b')\n",
    "    # picture becomes 7*7*32\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 128], stage=4, block='a', s=2)\n",
    "    # X = identity_block(X, 3, [32, 32, 64], stage=4, block='b')\n",
    "    # picture becomes 4*4*64\n",
    "\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 256], stage=5, block='a', s=2)\n",
    "    # X = identity_block(X, 3, [16, 16, 32], stage=5, block='b')\n",
    "    # picture becomes 2*2*128\n",
    "\n",
    "    # Stage 6\n",
    "    X = convolutional_block(X, f=3, filters=[256, 256, 512], stage=6, block='a', s=2)\n",
    "    # X = identity_block(X, 3, [128, 128, 256], stage=6, block='b')\n",
    "    # X = identity_block(X, 3, [128, 128, 256], stage=6, block='c')\n",
    "    # picture becomes 1*1*256\n",
    "\n",
    "    # # Stage 7\n",
    "    # X = convolutional_block(X, f=3, filters=[16, 16, 16], stage=7, block='a', s=2)\n",
    "    # X = identity_block(X, 3, [256, 256, 512], stage=7, block='b')\n",
    "    # # picture becomes 1*1*512\n",
    "\n",
    "    # Average Pooling\n",
    "    X = AveragePooling2D((2, 2), name='avg_pool')(X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='sigmoid', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)#,kernel_regularizer=tf.keras.regularizers.l1(0.1))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape = (100, 100, 1), classes = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='ADAM', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.compile(tf.keras.optimizers.Adam(learning_rate=0.001), loss=tf.keras.losses.MeanSquaredLogarithmicError(), metrics=['accuracy'])\n",
    "# model.compile(tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 100, 100, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_4 (ZeroPadding2  (None, 106, 106, 1)  0          ['input_5[0][0]']                \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 53, 53, 64)   320         ['zero_padding2d_4[0][0]']       \n",
      "                                                                                                  \n",
      " bn_conv1 (BatchNormalization)  (None, 53, 53, 64)   256         ['conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 53, 53, 64)   0           ['bn_conv1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 26, 26, 64)  0           ['activation_82[0][0]']          \n",
      "                                                                                                  \n",
      " res2a_branch2a (Conv2D)        (None, 26, 26, 16)   1040        ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " bn2a_branch2a (BatchNormalizat  (None, 26, 26, 16)  64          ['res2a_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 26, 26, 16)   0           ['bn2a_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res2a_branch2b (Conv2D)        (None, 26, 26, 16)   2320        ['activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " bn2a_branch2b (BatchNormalizat  (None, 26, 26, 16)  64          ['res2a_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 26, 26, 16)   0           ['bn2a_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res2a_branch2c (Conv2D)        (None, 26, 26, 32)   544         ['activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " res2a_branch1 (Conv2D)         (None, 26, 26, 32)   2080        ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " bn2a_branch2c (BatchNormalizat  (None, 26, 26, 32)  128         ['res2a_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " bn2a_branch1 (BatchNormalizati  (None, 26, 26, 32)  128         ['res2a_branch1[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 26, 26, 32)   0           ['bn2a_branch2c[0][0]',          \n",
      "                                                                  'bn2a_branch1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 26, 26, 32)   0           ['add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " res3a_branch2a (Conv2D)        (None, 13, 13, 32)   1056        ['activation_85[0][0]']          \n",
      "                                                                                                  \n",
      " bn3a_branch2a (BatchNormalizat  (None, 13, 13, 32)  128         ['res3a_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 13, 13, 32)   0           ['bn3a_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res3a_branch2b (Conv2D)        (None, 13, 13, 32)   9248        ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " bn3a_branch2b (BatchNormalizat  (None, 13, 13, 32)  128         ['res3a_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 13, 13, 32)   0           ['bn3a_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res3a_branch2c (Conv2D)        (None, 13, 13, 64)   2112        ['activation_87[0][0]']          \n",
      "                                                                                                  \n",
      " res3a_branch1 (Conv2D)         (None, 13, 13, 64)   2112        ['activation_85[0][0]']          \n",
      "                                                                                                  \n",
      " bn3a_branch2c (BatchNormalizat  (None, 13, 13, 64)  256         ['res3a_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " bn3a_branch1 (BatchNormalizati  (None, 13, 13, 64)  256         ['res3a_branch1[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, 13, 13, 64)   0           ['bn3a_branch2c[0][0]',          \n",
      "                                                                  'bn3a_branch1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 13, 13, 64)   0           ['add_27[0][0]']                 \n",
      "                                                                                                  \n",
      " res4a_branch2a (Conv2D)        (None, 7, 7, 64)     4160        ['activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " bn4a_branch2a (BatchNormalizat  (None, 7, 7, 64)    256         ['res4a_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 7, 7, 64)     0           ['bn4a_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res4a_branch2b (Conv2D)        (None, 7, 7, 64)     36928       ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " bn4a_branch2b (BatchNormalizat  (None, 7, 7, 64)    256         ['res4a_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 7, 7, 64)     0           ['bn4a_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res4a_branch2c (Conv2D)        (None, 7, 7, 128)    8320        ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " res4a_branch1 (Conv2D)         (None, 7, 7, 128)    8320        ['activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " bn4a_branch2c (BatchNormalizat  (None, 7, 7, 128)   512         ['res4a_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " bn4a_branch1 (BatchNormalizati  (None, 7, 7, 128)   512         ['res4a_branch1[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " add_28 (Add)                   (None, 7, 7, 128)    0           ['bn4a_branch2c[0][0]',          \n",
      "                                                                  'bn4a_branch1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 7, 7, 128)    0           ['add_28[0][0]']                 \n",
      "                                                                                                  \n",
      " res5a_branch2a (Conv2D)        (None, 4, 4, 128)    16512       ['activation_91[0][0]']          \n",
      "                                                                                                  \n",
      " bn5a_branch2a (BatchNormalizat  (None, 4, 4, 128)   512         ['res5a_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 4, 4, 128)    0           ['bn5a_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res5a_branch2b (Conv2D)        (None, 4, 4, 128)    147584      ['activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " bn5a_branch2b (BatchNormalizat  (None, 4, 4, 128)   512         ['res5a_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 4, 4, 128)    0           ['bn5a_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res5a_branch2c (Conv2D)        (None, 4, 4, 256)    33024       ['activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " res5a_branch1 (Conv2D)         (None, 4, 4, 256)    33024       ['activation_91[0][0]']          \n",
      "                                                                                                  \n",
      " bn5a_branch2c (BatchNormalizat  (None, 4, 4, 256)   1024        ['res5a_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " bn5a_branch1 (BatchNormalizati  (None, 4, 4, 256)   1024        ['res5a_branch1[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, 4, 4, 256)    0           ['bn5a_branch2c[0][0]',          \n",
      "                                                                  'bn5a_branch1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_94 (Activation)     (None, 4, 4, 256)    0           ['add_29[0][0]']                 \n",
      "                                                                                                  \n",
      " res6a_branch2a (Conv2D)        (None, 2, 2, 256)    65792       ['activation_94[0][0]']          \n",
      "                                                                                                  \n",
      " bn6a_branch2a (BatchNormalizat  (None, 2, 2, 256)   1024        ['res6a_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_95 (Activation)     (None, 2, 2, 256)    0           ['bn6a_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res6a_branch2b (Conv2D)        (None, 2, 2, 256)    590080      ['activation_95[0][0]']          \n",
      "                                                                                                  \n",
      " bn6a_branch2b (BatchNormalizat  (None, 2, 2, 256)   1024        ['res6a_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_96 (Activation)     (None, 2, 2, 256)    0           ['bn6a_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res6a_branch2c (Conv2D)        (None, 2, 2, 512)    131584      ['activation_96[0][0]']          \n",
      "                                                                                                  \n",
      " res6a_branch1 (Conv2D)         (None, 2, 2, 512)    131584      ['activation_94[0][0]']          \n",
      "                                                                                                  \n",
      " bn6a_branch2c (BatchNormalizat  (None, 2, 2, 512)   2048        ['res6a_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " bn6a_branch1 (BatchNormalizati  (None, 2, 2, 512)   2048        ['res6a_branch1[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " add_30 (Add)                   (None, 2, 2, 512)    0           ['bn6a_branch2c[0][0]',          \n",
      "                                                                  'bn6a_branch1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_97 (Activation)     (None, 2, 2, 512)    0           ['add_30[0][0]']                 \n",
      "                                                                                                  \n",
      " avg_pool (AveragePooling2D)    (None, 1, 1, 512)    0           ['activation_97[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 512)          0           ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      " fc11 (Dense)                   (None, 11)           5643        ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,245,547\n",
      "Trainable params: 1,239,467\n",
      "Non-trainable params: 6,080\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 125ms/step - loss: 2.3329e-06 - accuracy: 0.9400\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 1s 129ms/step - loss: 2.0477e-06 - accuracy: 0.9450\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 1s 125ms/step - loss: 2.3575e-06 - accuracy: 0.9200\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 2.1237e-06 - accuracy: 0.9100\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 1s 140ms/step - loss: 2.3113e-06 - accuracy: 0.9400\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 1s 135ms/step - loss: 2.1777e-06 - accuracy: 0.9100\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 1s 127ms/step - loss: 1.9859e-06 - accuracy: 0.9200\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 1s 134ms/step - loss: 2.2880e-06 - accuracy: 0.9400\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 1s 132ms/step - loss: 2.0824e-06 - accuracy: 0.9250\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 1.9179e-06 - accuracy: 0.9650\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 1s 137ms/step - loss: 1.9940e-06 - accuracy: 0.9150\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 1s 134ms/step - loss: 2.0658e-06 - accuracy: 0.9300\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 1s 129ms/step - loss: 2.6457e-06 - accuracy: 0.9150\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 1s 128ms/step - loss: 3.0891e-06 - accuracy: 0.9250\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 1s 138ms/step - loss: 4.3751e-06 - accuracy: 0.8850\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 1s 123ms/step - loss: 3.4255e-06 - accuracy: 0.9250\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 1s 124ms/step - loss: 3.1188e-06 - accuracy: 0.9300\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 1s 136ms/step - loss: 3.6054e-06 - accuracy: 0.8850\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 1s 130ms/step - loss: 3.9086e-06 - accuracy: 0.8850\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 1s 124ms/step - loss: 2.8917e-06 - accuracy: 0.9400\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 1s 135ms/step - loss: 2.7773e-06 - accuracy: 0.9300\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 1s 134ms/step - loss: 3.0034e-06 - accuracy: 0.9200\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 1s 123ms/step - loss: 2.8570e-06 - accuracy: 0.9200\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 1s 129ms/step - loss: 3.1610e-06 - accuracy: 0.9250\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 1s 138ms/step - loss: 2.4611e-06 - accuracy: 0.9150\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 1s 127ms/step - loss: 2.0864e-06 - accuracy: 0.9650\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 2.2394e-06 - accuracy: 0.9550\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 1s 135ms/step - loss: 2.1823e-06 - accuracy: 0.9150\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 1s 132ms/step - loss: 2.1761e-06 - accuracy: 0.9500\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 2.0210e-06 - accuracy: 0.9450\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 1s 140ms/step - loss: 2.4918e-06 - accuracy: 0.9400\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 1s 142ms/step - loss: 2.8481e-06 - accuracy: 0.9200\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 2.7105e-06 - accuracy: 0.9000\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 1s 128ms/step - loss: 2.7847e-06 - accuracy: 0.9100\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 1s 153ms/step - loss: 1.9832e-06 - accuracy: 0.9100\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 1s 126ms/step - loss: 2.3128e-06 - accuracy: 0.9200\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 1s 128ms/step - loss: 2.5178e-06 - accuracy: 0.8900\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 1s 174ms/step - loss: 2.2440e-06 - accuracy: 0.9650\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 1s 125ms/step - loss: 2.2137e-06 - accuracy: 0.9250\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 1s 131ms/step - loss: 2.8094e-06 - accuracy: 0.9050\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 1s 139ms/step - loss: 2.7529e-06 - accuracy: 0.9300\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 1s 137ms/step - loss: 2.2979e-06 - accuracy: 0.9450\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 1s 127ms/step - loss: 1.8856e-06 - accuracy: 0.9300\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 1s 133ms/step - loss: 2.4238e-06 - accuracy: 0.9400\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 1s 138ms/step - loss: 2.4122e-06 - accuracy: 0.9250\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 1s 124ms/step - loss: 2.9345e-06 - accuracy: 0.9300\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 1s 126ms/step - loss: 2.3724e-06 - accuracy: 0.9400\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 1s 137ms/step - loss: 2.0185e-06 - accuracy: 0.9100\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 1s 125ms/step - loss: 2.2862e-06 - accuracy: 0.9000\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 1s 127ms/step - loss: 2.6924e-06 - accuracy: 0.9300\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 1s 133ms/step - loss: 2.2060e-06 - accuracy: 0.9350\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 1s 125ms/step - loss: 2.0969e-06 - accuracy: 0.9050\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 1s 128ms/step - loss: 1.4485e-06 - accuracy: 0.9450\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 1s 134ms/step - loss: 2.3605e-06 - accuracy: 0.9400\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 1s 138ms/step - loss: 1.6611e-06 - accuracy: 0.9400\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 1s 132ms/step - loss: 1.9066e-06 - accuracy: 0.9600\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 1s 139ms/step - loss: 2.3918e-06 - accuracy: 0.9100\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 1s 138ms/step - loss: 2.1282e-06 - accuracy: 0.9150\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 1s 131ms/step - loss: 2.0688e-06 - accuracy: 0.9250\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 1s 145ms/step - loss: 2.0155e-06 - accuracy: 0.9700\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 1s 134ms/step - loss: 1.8466e-06 - accuracy: 0.9500\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 1s 131ms/step - loss: 1.8177e-06 - accuracy: 0.9500\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 1s 145ms/step - loss: 1.8190e-06 - accuracy: 0.9200\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 1s 135ms/step - loss: 2.0834e-06 - accuracy: 0.9350\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 1s 126ms/step - loss: 2.2592e-06 - accuracy: 0.9300\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 1s 136ms/step - loss: 1.8021e-06 - accuracy: 0.9200\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 1s 128ms/step - loss: 2.0749e-06 - accuracy: 0.9350\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 1s 128ms/step - loss: 1.9554e-06 - accuracy: 0.9450\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 1s 130ms/step - loss: 2.4406e-06 - accuracy: 0.9400\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 1s 131ms/step - loss: 2.5783e-06 - accuracy: 0.9150\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 1s 137ms/step - loss: 2.4368e-06 - accuracy: 0.9250\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 1s 137ms/step - loss: 1.8762e-06 - accuracy: 0.9650\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 1s 134ms/step - loss: 1.7993e-06 - accuracy: 0.9300\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 1s 128ms/step - loss: 1.6124e-06 - accuracy: 0.9350\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 1s 125ms/step - loss: 1.6917e-06 - accuracy: 0.9450\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 1s 130ms/step - loss: 1.6797e-06 - accuracy: 0.9100\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 1s 137ms/step - loss: 1.5506e-06 - accuracy: 0.9100\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 1.8144e-06 - accuracy: 0.9500\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 1s 129ms/step - loss: 1.5128e-06 - accuracy: 0.9400\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 1s 143ms/step - loss: 1.6037e-06 - accuracy: 0.9500\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 1.9035e-06 - accuracy: 0.9200\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 1s 133ms/step - loss: 1.9461e-06 - accuracy: 0.9400\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 1s 133ms/step - loss: 1.6279e-06 - accuracy: 0.9300\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 1.7900e-06 - accuracy: 0.9500\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 1s 126ms/step - loss: 2.3304e-06 - accuracy: 0.9200\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 1s 150ms/step - loss: 2.1623e-06 - accuracy: 0.9250\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 1s 130ms/step - loss: 1.8936e-06 - accuracy: 0.9250\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 1.7800e-06 - accuracy: 0.9200\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 1s 142ms/step - loss: 1.5372e-06 - accuracy: 0.9400\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 1s 142ms/step - loss: 1.6891e-06 - accuracy: 0.9550\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 1.7331e-06 - accuracy: 0.9200\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 1s 138ms/step - loss: 1.9276e-06 - accuracy: 0.9050\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 1s 145ms/step - loss: 2.2484e-06 - accuracy: 0.9600\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 2.3421e-06 - accuracy: 0.8800\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 1s 129ms/step - loss: 2.3551e-06 - accuracy: 0.9400\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 1s 158ms/step - loss: 1.9963e-06 - accuracy: 0.9450\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 1s 131ms/step - loss: 2.1631e-06 - accuracy: 0.9300\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 1s 127ms/step - loss: 1.7859e-06 - accuracy: 0.9600\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 1s 140ms/step - loss: 1.7446e-06 - accuracy: 0.9100\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 1s 130ms/step - loss: 1.7333e-06 - accuracy: 0.9400\n"
     ]
    }
   ],
   "source": [
    "rediction=model.fit(x_train,y_train,epochs=100,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1589520eec0>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rediction.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 35ms/step - loss: 3.4178e-05 - accuracy: 0.5530\n",
      "Loss = 3.417819971218705e-05\n",
      "Test Accuracy = 0.5529999732971191\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(x_test, y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 100, 1)\n",
      "[[0.00133592 0.00129825 0.00288841 0.0070498  0.00461522 0.00812897\n",
      "  0.00590414 0.00913697 0.01454535 0.01677093 0.03943607]]\n",
      "[0.00103848 0.0019484  0.00151322 0.00226987 0.00216795 0.00173062\n",
      " 0.0019393  0.0014     0.021      0.021      0.006     ]\n",
      "0.006524538621306419\n"
     ]
    }
   ],
   "source": [
    "Y_data=X[20000]/256\n",
    "Y_data=Y_data.reshape(1,100,100,-1)\n",
    "print(Y_data.shape)\n",
    "q=model.predict(Y_data)\n",
    "print(q)\n",
    "print(Y[20000])\n",
    "mse = tf.keras.losses.MeanAbsoluteError()\n",
    "error=mse(q, Y[20000]).numpy()\n",
    "print(error)\n",
    "# print(q-y_train[100])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3523a396672f5aa74d0ca7efbc5200bb5adbcd905681922dc84f6183b6dba551"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
