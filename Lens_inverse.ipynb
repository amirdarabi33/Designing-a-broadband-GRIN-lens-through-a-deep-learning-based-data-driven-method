{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adarabi3\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "from matplotlib.pyplot import imshow\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=[]\n",
    "datadir=\"C:/Users/adarabi3/OneDrive - Georgia Institute of Technology/Documents/MATLAB/Lens_data/Image_output/\"\n",
    "path = os.path.join(datadir)\n",
    "image_list = os.listdir(path)\n",
    "for img in image_list:\n",
    "    image_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "    image_array2=cv2.resize(image_array,(100,100))\n",
    "    # plt.imshow(image_array,cmap=\"gray\")\n",
    "    # plt.show()\n",
    "    # break\n",
    "    training_data.append([image_array2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21000, 18)\n",
      "(21000, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "X=[]\n",
    "for features in training_data:\n",
    "    X.append(features)    \n",
    "X=np.array(X).reshape(-1,100,100,1)\n",
    "Y_train = pd.read_csv(\"Data_param.csv\")\n",
    "Y= Y_train.to_numpy().reshape(-1,18)\n",
    "print(Y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 100, 100, 1)\n",
      "(1000, 100, 100, 1)\n",
      "(200, 18)\n",
      "(1000, 18)\n"
     ]
    }
   ],
   "source": [
    "x_train=X[0:200]#20000]\n",
    "x_test=X[20000:21001]\n",
    "y_train=Y[0:200]#20000]\n",
    "y_test=Y[20000:21001]\n",
    "x_train=x_train/255\n",
    "x_test=x_test/255\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    \"\"\"\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    # Second component of main path\n",
    "    X = Conv2D(F2,  kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path \n",
    "    X = Conv2D(F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    ##### SHORTCUT PATH #### \n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X) \n",
    "    \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (400, 400, 1), classes = 10):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*2-> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (2, 2), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    # picture becomes 100*100*16\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), strides=(2, 2))(X)\n",
    "    # piture bcomes 25*25*64\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [16, 16, 32], stage = 2, block='a', s = 1)\n",
    "    # X = identity_block(X, 3, [8, 8, 16], stage=2, block='b')\n",
    "    # picture becomes 13*13*16\n",
    "\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f=3, filters=[32, 32, 64], stage=3, block='a', s=2)\n",
    "    # X = identity_block(X, 3, [16, 16, 32], stage=3, block='b')\n",
    "    # picture becomes 7*7*32\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 128], stage=4, block='a', s=2)\n",
    "    # X = identity_block(X, 3, [32, 32, 64], stage=4, block='b')\n",
    "    # picture becomes 4*4*64\n",
    "\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 256], stage=5, block='a', s=2)\n",
    "    # X = identity_block(X, 3, [16, 16, 32], stage=5, block='b')\n",
    "    # picture becomes 2*2*128\n",
    "\n",
    "    # Stage 6\n",
    "    X = convolutional_block(X, f=3, filters=[256, 256, 512], stage=6, block='a', s=2)\n",
    "    # X = identity_block(X, 3, [128, 128, 256], stage=6, block='b')\n",
    "    # X = identity_block(X, 3, [128, 128, 256], stage=6, block='c')\n",
    "    # picture becomes 1*1*256\n",
    "\n",
    "    # # Stage 7\n",
    "    # X = convolutional_block(X, f=3, filters=[16, 16, 16], stage=7, block='a', s=2)\n",
    "    # X = identity_block(X, 3, [256, 256, 512], stage=7, block='b')\n",
    "    # # picture becomes 1*1*512\n",
    "\n",
    "    # Average Pooling\n",
    "    X = AveragePooling2D((2, 2), name='avg_pool')(X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='sigmoid', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)#,kernel_regularizer=tf.keras.regularizers.l1(0.1))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape = (100, 100, 1), classes = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='ADAM', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.compile(tf.keras.optimizers.Adam(learning_rate=0.001), loss=tf.keras.losses.MeanSquaredLogarithmicError(), metrics=['accuracy'])\n",
    "# model.compile(tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_23 (InputLayer)          [(None, 100, 100, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_22 (ZeroPadding  (None, 106, 106, 1)  0          ['input_23[0][0]']               \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 53, 53, 64)   320         ['zero_padding2d_22[0][0]']      \n",
      "                                                                                                  \n",
      " bn_conv1 (BatchNormalization)  (None, 53, 53, 64)   256         ['conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " activation_381 (Activation)    (None, 53, 53, 64)   0           ['bn_conv1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_22 (MaxPooling2D  (None, 26, 26, 64)  0           ['activation_381[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " res2a_branch2a (Conv2D)        (None, 26, 26, 16)   1040        ['max_pooling2d_22[0][0]']       \n",
      "                                                                                                  \n",
      " bn2a_branch2a (BatchNormalizat  (None, 26, 26, 16)  64          ['res2a_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_382 (Activation)    (None, 26, 26, 16)   0           ['bn2a_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res2a_branch2b (Conv2D)        (None, 26, 26, 16)   2320        ['activation_382[0][0]']         \n",
      "                                                                                                  \n",
      " bn2a_branch2b (BatchNormalizat  (None, 26, 26, 16)  64          ['res2a_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_383 (Activation)    (None, 26, 26, 16)   0           ['bn2a_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res2a_branch2c (Conv2D)        (None, 26, 26, 32)   544         ['activation_383[0][0]']         \n",
      "                                                                                                  \n",
      " res2a_branch1 (Conv2D)         (None, 26, 26, 32)   2080        ['max_pooling2d_22[0][0]']       \n",
      "                                                                                                  \n",
      " bn2a_branch2c (BatchNormalizat  (None, 26, 26, 32)  128         ['res2a_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " bn2a_branch1 (BatchNormalizati  (None, 26, 26, 32)  128         ['res2a_branch1[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " add_120 (Add)                  (None, 26, 26, 32)   0           ['bn2a_branch2c[0][0]',          \n",
      "                                                                  'bn2a_branch1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_384 (Activation)    (None, 26, 26, 32)   0           ['add_120[0][0]']                \n",
      "                                                                                                  \n",
      " res3a_branch2a (Conv2D)        (None, 13, 13, 32)   1056        ['activation_384[0][0]']         \n",
      "                                                                                                  \n",
      " bn3a_branch2a (BatchNormalizat  (None, 13, 13, 32)  128         ['res3a_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_385 (Activation)    (None, 13, 13, 32)   0           ['bn3a_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res3a_branch2b (Conv2D)        (None, 13, 13, 32)   9248        ['activation_385[0][0]']         \n",
      "                                                                                                  \n",
      " bn3a_branch2b (BatchNormalizat  (None, 13, 13, 32)  128         ['res3a_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_386 (Activation)    (None, 13, 13, 32)   0           ['bn3a_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res3a_branch2c (Conv2D)        (None, 13, 13, 64)   2112        ['activation_386[0][0]']         \n",
      "                                                                                                  \n",
      " res3a_branch1 (Conv2D)         (None, 13, 13, 64)   2112        ['activation_384[0][0]']         \n",
      "                                                                                                  \n",
      " bn3a_branch2c (BatchNormalizat  (None, 13, 13, 64)  256         ['res3a_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " bn3a_branch1 (BatchNormalizati  (None, 13, 13, 64)  256         ['res3a_branch1[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " add_121 (Add)                  (None, 13, 13, 64)   0           ['bn3a_branch2c[0][0]',          \n",
      "                                                                  'bn3a_branch1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_387 (Activation)    (None, 13, 13, 64)   0           ['add_121[0][0]']                \n",
      "                                                                                                  \n",
      " res4a_branch2a (Conv2D)        (None, 7, 7, 64)     4160        ['activation_387[0][0]']         \n",
      "                                                                                                  \n",
      " bn4a_branch2a (BatchNormalizat  (None, 7, 7, 64)    256         ['res4a_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_388 (Activation)    (None, 7, 7, 64)     0           ['bn4a_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res4a_branch2b (Conv2D)        (None, 7, 7, 64)     36928       ['activation_388[0][0]']         \n",
      "                                                                                                  \n",
      " bn4a_branch2b (BatchNormalizat  (None, 7, 7, 64)    256         ['res4a_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_389 (Activation)    (None, 7, 7, 64)     0           ['bn4a_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res4a_branch2c (Conv2D)        (None, 7, 7, 128)    8320        ['activation_389[0][0]']         \n",
      "                                                                                                  \n",
      " res4a_branch1 (Conv2D)         (None, 7, 7, 128)    8320        ['activation_387[0][0]']         \n",
      "                                                                                                  \n",
      " bn4a_branch2c (BatchNormalizat  (None, 7, 7, 128)   512         ['res4a_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " bn4a_branch1 (BatchNormalizati  (None, 7, 7, 128)   512         ['res4a_branch1[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " add_122 (Add)                  (None, 7, 7, 128)    0           ['bn4a_branch2c[0][0]',          \n",
      "                                                                  'bn4a_branch1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_390 (Activation)    (None, 7, 7, 128)    0           ['add_122[0][0]']                \n",
      "                                                                                                  \n",
      " res5a_branch2a (Conv2D)        (None, 4, 4, 128)    16512       ['activation_390[0][0]']         \n",
      "                                                                                                  \n",
      " bn5a_branch2a (BatchNormalizat  (None, 4, 4, 128)   512         ['res5a_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_391 (Activation)    (None, 4, 4, 128)    0           ['bn5a_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res5a_branch2b (Conv2D)        (None, 4, 4, 128)    147584      ['activation_391[0][0]']         \n",
      "                                                                                                  \n",
      " bn5a_branch2b (BatchNormalizat  (None, 4, 4, 128)   512         ['res5a_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_392 (Activation)    (None, 4, 4, 128)    0           ['bn5a_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res5a_branch2c (Conv2D)        (None, 4, 4, 256)    33024       ['activation_392[0][0]']         \n",
      "                                                                                                  \n",
      " res5a_branch1 (Conv2D)         (None, 4, 4, 256)    33024       ['activation_390[0][0]']         \n",
      "                                                                                                  \n",
      " bn5a_branch2c (BatchNormalizat  (None, 4, 4, 256)   1024        ['res5a_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " bn5a_branch1 (BatchNormalizati  (None, 4, 4, 256)   1024        ['res5a_branch1[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " add_123 (Add)                  (None, 4, 4, 256)    0           ['bn5a_branch2c[0][0]',          \n",
      "                                                                  'bn5a_branch1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_393 (Activation)    (None, 4, 4, 256)    0           ['add_123[0][0]']                \n",
      "                                                                                                  \n",
      " res6a_branch2a (Conv2D)        (None, 2, 2, 256)    65792       ['activation_393[0][0]']         \n",
      "                                                                                                  \n",
      " bn6a_branch2a (BatchNormalizat  (None, 2, 2, 256)   1024        ['res6a_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_394 (Activation)    (None, 2, 2, 256)    0           ['bn6a_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res6a_branch2b (Conv2D)        (None, 2, 2, 256)    590080      ['activation_394[0][0]']         \n",
      "                                                                                                  \n",
      " bn6a_branch2b (BatchNormalizat  (None, 2, 2, 256)   1024        ['res6a_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_395 (Activation)    (None, 2, 2, 256)    0           ['bn6a_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res6a_branch2c (Conv2D)        (None, 2, 2, 512)    131584      ['activation_395[0][0]']         \n",
      "                                                                                                  \n",
      " res6a_branch1 (Conv2D)         (None, 2, 2, 512)    131584      ['activation_393[0][0]']         \n",
      "                                                                                                  \n",
      " bn6a_branch2c (BatchNormalizat  (None, 2, 2, 512)   2048        ['res6a_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " bn6a_branch1 (BatchNormalizati  (None, 2, 2, 512)   2048        ['res6a_branch1[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " add_124 (Add)                  (None, 2, 2, 512)    0           ['bn6a_branch2c[0][0]',          \n",
      "                                                                  'bn6a_branch1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_396 (Activation)    (None, 2, 2, 512)    0           ['add_124[0][0]']                \n",
      "                                                                                                  \n",
      " avg_pool (AveragePooling2D)    (None, 1, 1, 512)    0           ['activation_396[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_21 (Flatten)           (None, 512)          0           ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      " fc18 (Dense)                   (None, 18)           9234        ['flatten_21[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,249,138\n",
      "Trainable params: 1,243,058\n",
      "Non-trainable params: 6,080\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 137ms/step - loss: 1.1514e-06 - accuracy: 0.9500\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 1s 159ms/step - loss: 1.1716e-06 - accuracy: 0.9350\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 1.3604e-06 - accuracy: 0.9450\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 1s 133ms/step - loss: 1.2693e-06 - accuracy: 0.9450\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 1s 149ms/step - loss: 1.0802e-06 - accuracy: 0.9400\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 1s 132ms/step - loss: 1.1440e-06 - accuracy: 0.9400\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 1s 139ms/step - loss: 1.0812e-06 - accuracy: 0.9250\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 1s 151ms/step - loss: 1.0869e-06 - accuracy: 0.9600\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 1s 132ms/step - loss: 1.1241e-06 - accuracy: 0.9100\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 1s 132ms/step - loss: 9.9305e-07 - accuracy: 0.9550\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 1s 179ms/step - loss: 1.1056e-06 - accuracy: 0.9200\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 1s 141ms/step - loss: 1.0197e-06 - accuracy: 0.9200\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 1s 131ms/step - loss: 1.0473e-06 - accuracy: 0.9450\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 1s 174ms/step - loss: 1.3286e-06 - accuracy: 0.9000\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 1s 139ms/step - loss: 1.3957e-06 - accuracy: 0.9450\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 1s 143ms/step - loss: 1.1342e-06 - accuracy: 0.9400\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 1s 200ms/step - loss: 1.2746e-06 - accuracy: 0.9600\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 1s 127ms/step - loss: 1.5005e-06 - accuracy: 0.9500\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 1s 168ms/step - loss: 1.8457e-06 - accuracy: 0.9150\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 1s 170ms/step - loss: 1.9639e-06 - accuracy: 0.9050\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 1.6783e-06 - accuracy: 0.8800\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 1.2841e-06 - accuracy: 0.9150\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 1s 214ms/step - loss: 1.2496e-06 - accuracy: 0.9250\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 1s 130ms/step - loss: 1.5211e-06 - accuracy: 0.9400\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 2s 244ms/step - loss: 1.5825e-06 - accuracy: 0.9150\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 1s 144ms/step - loss: 1.3240e-06 - accuracy: 0.9500\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 1s 169ms/step - loss: 1.1530e-06 - accuracy: 0.9450\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 1s 200ms/step - loss: 1.1213e-06 - accuracy: 0.9400\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 1s 129ms/step - loss: 1.0515e-06 - accuracy: 0.9000\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 1.0824e-06 - accuracy: 0.9200\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 1s 162ms/step - loss: 1.0901e-06 - accuracy: 0.9250\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 1s 124ms/step - loss: 1.0560e-06 - accuracy: 0.9500\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 1s 159ms/step - loss: 1.0068e-06 - accuracy: 0.9600\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 1s 154ms/step - loss: 1.3472e-06 - accuracy: 0.9300\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 1s 123ms/step - loss: 1.1492e-06 - accuracy: 0.9550\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 1s 150ms/step - loss: 1.2872e-06 - accuracy: 0.9100\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 1s 154ms/step - loss: 1.1978e-06 - accuracy: 0.9350\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 1.2775e-06 - accuracy: 0.9050\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 1s 154ms/step - loss: 1.2408e-06 - accuracy: 0.9600\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 1s 155ms/step - loss: 1.5009e-06 - accuracy: 0.9000\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 1.3650e-06 - accuracy: 0.9400\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 1s 151ms/step - loss: 1.0945e-06 - accuracy: 0.9450\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 1s 169ms/step - loss: 9.9126e-07 - accuracy: 0.9600\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 1.0437e-06 - accuracy: 0.9350\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 1s 153ms/step - loss: 9.6333e-07 - accuracy: 0.9450\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 1s 164ms/step - loss: 9.9969e-07 - accuracy: 0.9350\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 1s 119ms/step - loss: 1.0072e-06 - accuracy: 0.9400\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 1s 148ms/step - loss: 9.8584e-07 - accuracy: 0.9550\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 1s 169ms/step - loss: 9.2684e-07 - accuracy: 0.9500\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 1.0402e-06 - accuracy: 0.9300\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 1s 158ms/step - loss: 8.7287e-07 - accuracy: 0.9300\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 1s 158ms/step - loss: 1.4444e-06 - accuracy: 0.9100\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 1s 124ms/step - loss: 1.2720e-06 - accuracy: 0.9250\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 1s 155ms/step - loss: 1.3761e-06 - accuracy: 0.9200\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 1s 170ms/step - loss: 9.6623e-07 - accuracy: 0.9500\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 1s 123ms/step - loss: 1.2894e-06 - accuracy: 0.9350\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 1s 154ms/step - loss: 9.9909e-07 - accuracy: 0.9050\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 1s 161ms/step - loss: 1.0855e-06 - accuracy: 0.9550\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 1.2917e-06 - accuracy: 0.9400\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 1s 183ms/step - loss: 1.1561e-06 - accuracy: 0.9150\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 1s 162ms/step - loss: 1.0038e-06 - accuracy: 0.9300\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 1.2016e-06 - accuracy: 0.9600\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 1s 167ms/step - loss: 9.7059e-07 - accuracy: 0.9500\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 1s 178ms/step - loss: 8.3576e-07 - accuracy: 0.9350\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 1s 123ms/step - loss: 1.0478e-06 - accuracy: 0.9300\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 8.4004e-07 - accuracy: 0.9650\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 1s 135ms/step - loss: 9.2041e-07 - accuracy: 0.9250\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 1s 130ms/step - loss: 1.0283e-06 - accuracy: 0.9300\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 1s 167ms/step - loss: 8.6952e-07 - accuracy: 0.9200\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 1s 140ms/step - loss: 9.1962e-07 - accuracy: 0.9450\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 1s 145ms/step - loss: 1.1435e-06 - accuracy: 0.9450\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 1s 163ms/step - loss: 1.1175e-06 - accuracy: 0.9350\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 1s 134ms/step - loss: 1.0670e-06 - accuracy: 0.9300\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 1s 165ms/step - loss: 1.0713e-06 - accuracy: 0.9600\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 1s 199ms/step - loss: 9.4600e-07 - accuracy: 0.9400\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 1s 125ms/step - loss: 1.0701e-06 - accuracy: 0.9300\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 1.2271e-06 - accuracy: 0.9450\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 1s 152ms/step - loss: 1.2673e-06 - accuracy: 0.9150\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 1.5457e-06 - accuracy: 0.9150\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 1.3034e-06 - accuracy: 0.9400\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 1s 164ms/step - loss: 1.1942e-06 - accuracy: 0.9150\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 1s 126ms/step - loss: 1.2089e-06 - accuracy: 0.9450\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 1.4782e-06 - accuracy: 0.9600\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 1s 156ms/step - loss: 1.0343e-06 - accuracy: 0.9550\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 1s 127ms/step - loss: 1.3311e-06 - accuracy: 0.9150\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 1.2658e-06 - accuracy: 0.9550\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 1s 138ms/step - loss: 1.2228e-06 - accuracy: 0.9200\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 1s 133ms/step - loss: 1.1757e-06 - accuracy: 0.9350\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 1.5387e-06 - accuracy: 0.9100\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 1s 124ms/step - loss: 1.1515e-06 - accuracy: 0.9250\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 1s 152ms/step - loss: 1.1848e-06 - accuracy: 0.9200\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 1s 161ms/step - loss: 1.0259e-06 - accuracy: 0.9450\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 1s 124ms/step - loss: 1.1023e-06 - accuracy: 0.9400\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 9.1555e-07 - accuracy: 0.9350\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 1s 150ms/step - loss: 1.0798e-06 - accuracy: 0.9050\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 1s 125ms/step - loss: 1.4374e-06 - accuracy: 0.9550\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 1s 155ms/step - loss: 1.1185e-06 - accuracy: 0.9350\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 1s 143ms/step - loss: 1.4346e-06 - accuracy: 0.9300\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 1s 125ms/step - loss: 1.1624e-06 - accuracy: 0.9050\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 1s 152ms/step - loss: 9.7720e-07 - accuracy: 0.9400\n"
     ]
    }
   ],
   "source": [
    "rediction=model.fit(x_train,y_train,epochs=100,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1df8d208e80>]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rediction.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 27ms/step - loss: 5.4551e-05 - accuracy: 0.5940\n",
      "Loss = 5.455149948829785e-05\n",
      "Test Accuracy = 0.593999981880188\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(x_test, y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 100, 1)\n",
      "[[0.00040597 0.00083274 0.00062922 0.00086486 0.00241703 0.00248325\n",
      "  0.00189826 0.00258115 0.00194329 0.00220487 0.00286713 0.00093749\n",
      "  0.00067753 0.00062498 0.00064492 0.01525083 0.01760367 0.00838861]]\n",
      "[0.         0.         0.         0.         0.00230291 0.00158579\n",
      " 0.00196822 0.0019     0.00196822 0.00158579 0.00230291 0.\n",
      " 0.         0.         0.         0.014      0.017      0.009     ]\n",
      "0.0006141391932033002\n"
     ]
    }
   ],
   "source": [
    "Y_data=x_train[10]\n",
    "Y_data=Y_data.reshape(1,100,100,-1)\n",
    "print(Y_data.shape)\n",
    "q=model.predict(Y_data)\n",
    "print(q)\n",
    "print(y_train[10])\n",
    "mse = tf.keras.losses.MeanAbsoluteError()\n",
    "error=mse(q, y_train[10]).numpy()\n",
    "print(error)\n",
    "# print(q-y_train[100])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3523a396672f5aa74d0ca7efbc5200bb5adbcd905681922dc84f6183b6dba551"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
